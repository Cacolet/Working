{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据，处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "train_datas = pd.read_csv('./work/train.csv')\n",
    "test_datas = pd.read_csv('./work/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datas = train_datas.loc[:, ~train_datas.columns.str.contains(\"^Unnamed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ascore', 'category', 'description', 'ein', 'tot_exp', 'admin_exp_p',\n",
      "       'fund_eff', 'fund_exp_p', 'program_exp_p', 'fscore', 'leader',\n",
      "       'leader_comp', 'leader_comp_p', 'motto', 'name', 'tot_rev', 'score',\n",
      "       'state', 'subcategory', 'size', 'program_exp', 'fund_exp', 'admin_exp'],\n",
      "      dtype='object')\n",
      "['ascore', 'tot_exp', 'admin_exp_p', 'fund_eff', 'fund_exp_p', 'program_exp_p', 'fscore', 'leader_comp', 'leader_comp_p', 'tot_rev', 'score', 'program_exp', 'fund_exp', 'admin_exp']\n",
      "['ascore', 'tot_exp', 'admin_exp_p', 'fund_eff', 'fund_exp_p', 'program_exp_p', 'fscore', 'leader_comp', 'leader_comp_p', 'tot_rev', 'program_exp', 'fund_exp', 'admin_exp']\n",
      "(7398, 14) (1000, 13)\n",
      "                 ascore   tot_exp  admin_exp_p      fund_eff  fund_exp_p  \\\n",
      "ascore         1.000000  0.083334    -0.190062  6.322378e-03   -0.001976   \n",
      "tot_exp        0.083334  1.000000    -0.087523 -1.891372e-03   -0.001891   \n",
      "admin_exp_p   -0.190062 -0.087523     1.000000 -1.995143e-03   -0.001996   \n",
      "fund_eff       0.006322 -0.001891    -0.001995  1.000000e+00   -0.000127   \n",
      "fund_exp_p    -0.001976 -0.001891    -0.001996 -1.267417e-04    1.000000   \n",
      "program_exp_p  0.020087  0.011793    -0.078778  7.378681e-07   -0.009983   \n",
      "fscore         0.143811  0.051575    -0.403969  1.669943e-03   -0.115206   \n",
      "leader_comp    0.131513  0.343381     0.008248  1.733837e-01   -0.014282   \n",
      "leader_comp_p -0.000100 -0.002745    -0.002896  1.032487e-01   -0.000148   \n",
      "tot_rev        0.082951  0.989927    -0.082083 -1.877658e-03   -0.002507   \n",
      "score          0.685313  0.080121    -0.352477  2.051515e-03    0.002052   \n",
      "program_exp    0.081780  0.996622    -0.099024 -1.841044e-03   -0.001841   \n",
      "fund_exp       0.075379  0.767202    -0.051161 -1.579650e-03   -0.001580   \n",
      "admin_exp      0.066952  0.747279     0.068920 -2.052223e-03   -0.002052   \n",
      "\n",
      "               program_exp_p    fscore  leader_comp  leader_comp_p   tot_rev  \\\n",
      "ascore          2.008681e-02  0.143811     0.131513  -9.972031e-05  0.082951   \n",
      "tot_exp         1.179342e-02  0.051575     0.343381  -2.744978e-03  0.989927   \n",
      "admin_exp_p    -7.877820e-02 -0.403969     0.008248  -2.895816e-03 -0.082083   \n",
      "fund_eff        7.378681e-07  0.001670     0.173384   1.032487e-01 -0.001878   \n",
      "fund_exp_p     -9.983091e-03 -0.115206    -0.014282  -1.479145e-04 -0.002507   \n",
      "program_exp_p   1.000000e+00  0.072783    -0.011457   8.516733e-07  0.011070   \n",
      "fscore          7.278323e-02  1.000000     0.056298   2.419683e-03  0.057537   \n",
      "leader_comp    -1.145731e-02  0.056298     1.000000   1.313160e-02  0.340558   \n",
      "leader_comp_p   8.516733e-07  0.002420     0.013132   1.000000e+00 -0.003573   \n",
      "tot_rev         1.106972e-02  0.057537     0.340558  -3.572920e-03  1.000000   \n",
      "score           6.793009e-02  0.665862     0.117384  -1.627374e-01  0.083977   \n",
      "program_exp     1.378170e-02  0.059260     0.323645  -3.452430e-03  0.988169   \n",
      "fund_exp       -3.870382e-03 -0.025111     0.313617  -2.293027e-03  0.751463   \n",
      "admin_exp      -2.020383e-03  0.001821     0.442113  -2.978563e-03  0.727679   \n",
      "\n",
      "                  score  program_exp  fund_exp  admin_exp  \n",
      "ascore         0.685313     0.081780  0.075379   0.066952  \n",
      "tot_exp        0.080121     0.996622  0.767202   0.747279  \n",
      "admin_exp_p   -0.352477    -0.099024 -0.051161   0.068920  \n",
      "fund_eff       0.002052    -0.001841 -0.001580  -0.002052  \n",
      "fund_exp_p     0.002052    -0.001841 -0.001580  -0.002052  \n",
      "program_exp_p  0.067930     0.013782 -0.003870  -0.002020  \n",
      "fscore         0.665862     0.059260 -0.025111   0.001821  \n",
      "leader_comp    0.117384     0.323645  0.313617   0.442113  \n",
      "leader_comp_p -0.162737    -0.003452 -0.002293  -0.002979  \n",
      "tot_rev        0.083977     0.988169  0.751463   0.727679  \n",
      "score          1.000000     0.085122  0.012378   0.043442  \n",
      "program_exp    0.085122     1.000000  0.722738   0.700591  \n",
      "fund_exp       0.012378     0.722738  1.000000   0.698552  \n",
      "admin_exp      0.043442     0.700591  0.698552   1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 清理数据\n",
    "c = train_datas.columns\n",
    "print(c)\n",
    "clean_c = ['category', 'description', 'ein', 'leader',\n",
    "           'motto', 'name', 'state', 'subcategory', 'size']\n",
    "keys = []\n",
    "for i in c:\n",
    "    if i not in clean_c:\n",
    "        keys.append(i)\n",
    "print(keys)\n",
    "\n",
    "train_datas = train_datas[keys]\n",
    "for key in keys:\n",
    "        train_datas[key] = pd.to_numeric(train_datas[key], errors='coerce').fillna(0)\n",
    "        train_datas[key] = train_datas[key].replace(0, train_datas[key].median())\n",
    "\n",
    "train_datas.drop(labels=[1184, 4476], inplace=True)\n",
    "count = 0\n",
    "for score in train_datas['score'].values:\n",
    "    if score > 100 or score <= 0:\n",
    "        print(score, count)\n",
    "    count += 1\n",
    "keys.remove('score')\n",
    "print(keys)\n",
    "test_datas = test_datas[keys]\n",
    "for key in keys:\n",
    "    test_datas[key] = pd.to_numeric(test_datas[key], errors='coerce').fillna(0)\n",
    "    test_datas[key] = test_datas[key].replace(0, test_datas[key].median())\n",
    "print(train_datas.shape, test_datas.shape)\n",
    "print(train_datas.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5918, 1) (5918, 13) (1000, 13) (1480, 13) (1480, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 标签特征分离\n",
    "train_labels = train_datas[['score']].values.astype('float32')\n",
    "train_dataset = train_datas[keys].values.astype('float32')\n",
    "split = int(train_dataset.shape[0]*0.8)\n",
    "seed = np.random.randint(10000)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(train_labels)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(train_dataset)\n",
    "val_dataset = train_dataset[split:, :]\n",
    "val_labels = train_labels[split:, :]\n",
    "train_dataset = train_dataset[:split, :]\n",
    "train_labels = train_labels[:split, :]\n",
    "test_dataset = test_datas.values.astype('float32')\n",
    "print(train_labels.shape, train_dataset.shape, test_dataset.shape, val_dataset.shape, val_labels.shape)\n",
    "\n",
    "# 数据标准化\n",
    "feature_mean = train_dataset.mean()\n",
    "feature_std = train_dataset.std()\n",
    "label_mean = train_labels.mean()\n",
    "label_std = train_labels.std()\n",
    "\n",
    "train_dataset = (train_dataset - feature_mean) / feature_std\n",
    "test_dataset = (test_dataset - feature_mean) / feature_std\n",
    "val_dataset = (val_dataset - feature_mean) / feature_std\n",
    "train_labels = (train_labels - label_mean) / label_std\n",
    "val_labels = (val_labels - label_mean) / label_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=train_dataset.shape[-1], out_features=16),\n",
    "    nn.BatchNorm1D(num_features=16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=16, out_features=8),\n",
    "    nn.BatchNorm1D(num_features=8),\n",
    "    nn.ReLU(),    \n",
    "    nn.Linear(in_features=8, out_features=1)\n",
    ")\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=1e-2, parameters=model.parameters())\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "D:\\anaconda\\lib\\site-packages\\paddle\\nn\\layer\\norm.py:652: UserWarning: When training, we now always track global mean and variance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs/Epoch:100/1 Train MSELoss:0.8662928736404233\n",
      "Epochs/Epoch:100/1 Val MSELoss:79.36422948530137\n",
      "Epochs/Epoch:100/2 Train MSELoss:0.7967641909161339\n",
      "Epochs/Epoch:100/2 Val MSELoss:76.23801385132148\n",
      "Epochs/Epoch:100/3 Train MSELoss:0.7956313485198695\n",
      "Epochs/Epoch:100/3 Val MSELoss:81.6086545732226\n",
      "Epochs/Epoch:100/4 Train MSELoss:0.8068522785830757\n",
      "Epochs/Epoch:100/4 Val MSELoss:89.96068360010199\n",
      "Epochs/Epoch:100/5 Train MSELoss:0.7983816389156424\n",
      "Epochs/Epoch:100/5 Val MSELoss:84.04374363167865\n",
      "Epochs/Epoch:100/6 Train MSELoss:0.7625259291380644\n",
      "Epochs/Epoch:100/6 Val MSELoss:82.00356047158401\n",
      "Epochs/Epoch:100/7 Train MSELoss:0.7637538367315478\n",
      "Epochs/Epoch:100/7 Val MSELoss:72.25186948505426\n",
      "Epochs/Epoch:100/8 Train MSELoss:0.7346142600088016\n",
      "Epochs/Epoch:100/8 Val MSELoss:81.02978925035461\n",
      "Epochs/Epoch:100/9 Train MSELoss:0.7167169481677853\n",
      "Epochs/Epoch:100/9 Val MSELoss:82.848848801964\n",
      "Epochs/Epoch:100/10 Train MSELoss:0.747574650965955\n",
      "Epochs/Epoch:100/10 Val MSELoss:79.36409502646192\n",
      "Epochs/Epoch:100/11 Train MSELoss:0.747414787016485\n",
      "Epochs/Epoch:100/11 Val MSELoss:76.49102486260848\n",
      "Epochs/Epoch:100/12 Train MSELoss:0.7415426424502031\n",
      "Epochs/Epoch:100/12 Val MSELoss:88.51919844191666\n",
      "Epochs/Epoch:100/13 Train MSELoss:0.7459047859453637\n",
      "Epochs/Epoch:100/13 Val MSELoss:84.56417017580844\n",
      "Epochs/Epoch:100/14 Train MSELoss:0.7452635825004267\n",
      "Epochs/Epoch:100/14 Val MSELoss:82.47790031671092\n",
      "Epochs/Epoch:100/15 Train MSELoss:0.7267813788645942\n",
      "Epochs/Epoch:100/15 Val MSELoss:117.5416230435464\n",
      "Epochs/Epoch:100/16 Train MSELoss:0.7359614884075911\n",
      "Epochs/Epoch:100/16 Val MSELoss:88.97705133480461\n",
      "Epochs/Epoch:100/17 Train MSELoss:0.7488268095514049\n",
      "Epochs/Epoch:100/17 Val MSELoss:91.13735654291223\n",
      "Epochs/Epoch:100/18 Train MSELoss:0.7431719781749923\n",
      "Epochs/Epoch:100/18 Val MSELoss:80.8577992621956\n",
      "Epochs/Epoch:100/19 Train MSELoss:0.7284639576530975\n",
      "Epochs/Epoch:100/19 Val MSELoss:79.51555313333768\n",
      "Epochs/Epoch:100/20 Train MSELoss:0.7178186408203581\n",
      "Epochs/Epoch:100/20 Val MSELoss:88.13825050242126\n",
      "Epochs/Epoch:100/21 Train MSELoss:0.7246553123645161\n",
      "Epochs/Epoch:100/21 Val MSELoss:84.72405910765566\n",
      "Epochs/Epoch:100/22 Train MSELoss:0.7204626726553492\n",
      "Epochs/Epoch:100/22 Val MSELoss:78.66533515659287\n",
      "Epochs/Epoch:100/23 Train MSELoss:0.7204936821337627\n",
      "Epochs/Epoch:100/23 Val MSELoss:84.20497423278115\n",
      "Epochs/Epoch:100/24 Train MSELoss:0.7226313962398664\n",
      "Epochs/Epoch:100/24 Val MSELoss:89.95376917201143\n",
      "Epochs/Epoch:100/25 Train MSELoss:0.7071588224043017\n",
      "Epochs/Epoch:100/25 Val MSELoss:75.56105303012536\n",
      "Epochs/Epoch:100/26 Train MSELoss:0.7290961188466653\n",
      "Epochs/Epoch:100/26 Val MSELoss:80.42893587588357\n",
      "Epochs/Epoch:100/27 Train MSELoss:0.7088895558339098\n",
      "Epochs/Epoch:100/27 Val MSELoss:89.6583341400983\n",
      "Epochs/Epoch:100/28 Train MSELoss:0.7177690078058968\n",
      "Epochs/Epoch:100/28 Val MSELoss:84.11500157944936\n",
      "Epochs/Epoch:100/29 Train MSELoss:0.7125296970910352\n",
      "Epochs/Epoch:100/29 Val MSELoss:87.91900499648642\n",
      "Epochs/Epoch:100/30 Train MSELoss:0.7159575317864832\n",
      "Epochs/Epoch:100/30 Val MSELoss:84.79483218636065\n",
      "Epochs/Epoch:100/31 Train MSELoss:0.7239760447131551\n",
      "Epochs/Epoch:100/31 Val MSELoss:90.68254272877486\n",
      "Epochs/Epoch:100/32 Train MSELoss:0.6973870660623779\n",
      "Epochs/Epoch:100/32 Val MSELoss:80.81160268116285\n",
      "Epochs/Epoch:100/33 Train MSELoss:0.7227829467991124\n",
      "Epochs/Epoch:100/33 Val MSELoss:79.42892754815406\n",
      "Epochs/Epoch:100/34 Train MSELoss:0.7234551023044016\n",
      "Epochs/Epoch:100/34 Val MSELoss:78.2903676758077\n",
      "Epochs/Epoch:100/35 Train MSELoss:0.6940879799101664\n",
      "Epochs/Epoch:100/35 Val MSELoss:83.73427554940419\n",
      "Epochs/Epoch:100/36 Train MSELoss:0.7021971088226723\n",
      "Epochs/Epoch:100/36 Val MSELoss:77.61375952960692\n",
      "Epochs/Epoch:100/37 Train MSELoss:0.7077182340233222\n",
      "Epochs/Epoch:100/37 Val MSELoss:77.75265486672897\n",
      "Epochs/Epoch:100/38 Train MSELoss:0.7115029273959605\n",
      "Epochs/Epoch:100/38 Val MSELoss:78.32554764074027\n",
      "Epochs/Epoch:100/39 Train MSELoss:0.6903480708437122\n",
      "Epochs/Epoch:100/39 Val MSELoss:76.79560434080018\n",
      "Epochs/Epoch:100/40 Train MSELoss:0.6849485458401234\n",
      "Epochs/Epoch:100/40 Val MSELoss:80.53669166472541\n",
      "Epochs/Epoch:100/41 Train MSELoss:0.6933546621838341\n",
      "Epochs/Epoch:100/41 Val MSELoss:84.04437243796022\n",
      "Epochs/Epoch:100/42 Train MSELoss:0.6903129111489524\n",
      "Epochs/Epoch:100/42 Val MSELoss:84.85778407546447\n",
      "Epochs/Epoch:100/43 Train MSELoss:0.6922455029967038\n",
      "Epochs/Epoch:100/43 Val MSELoss:87.09800522131818\n",
      "Epochs/Epoch:100/44 Train MSELoss:0.7027792838280615\n",
      "Epochs/Epoch:100/44 Val MSELoss:75.10984345082083\n",
      "Epochs/Epoch:100/45 Train MSELoss:0.7073713264063649\n",
      "Epochs/Epoch:100/45 Val MSELoss:78.56898449457772\n",
      "Epochs/Epoch:100/46 Train MSELoss:0.7033227009941703\n",
      "Epochs/Epoch:100/46 Val MSELoss:78.40052632190181\n",
      "Epochs/Epoch:100/47 Train MSELoss:0.7069940848842912\n",
      "Epochs/Epoch:100/47 Val MSELoss:72.68379337926693\n",
      "Epochs/Epoch:100/48 Train MSELoss:0.692595004549493\n",
      "Epochs/Epoch:100/48 Val MSELoss:91.49121107319414\n",
      "Epochs/Epoch:100/49 Train MSELoss:0.689631132327992\n",
      "Epochs/Epoch:100/49 Val MSELoss:72.51937376986339\n",
      "Epochs/Epoch:100/50 Train MSELoss:0.6959011877036613\n",
      "Epochs/Epoch:100/50 Val MSELoss:71.36951156864536\n",
      "Epochs/Epoch:100/51 Train MSELoss:0.6899183011897232\n",
      "Epochs/Epoch:100/51 Val MSELoss:85.02187425696162\n",
      "Epochs/Epoch:100/52 Train MSELoss:0.6851256437923597\n",
      "Epochs/Epoch:100/52 Val MSELoss:87.67783407176678\n",
      "Epochs/Epoch:100/53 Train MSELoss:0.707909066553997\n",
      "Epochs/Epoch:100/53 Val MSELoss:71.880043248277\n",
      "Epochs/Epoch:100/54 Train MSELoss:0.7005939514416716\n",
      "Epochs/Epoch:100/54 Val MSELoss:80.03316187546837\n",
      "Epochs/Epoch:100/55 Train MSELoss:0.7147344426940316\n",
      "Epochs/Epoch:100/55 Val MSELoss:74.36470370408969\n",
      "Epochs/Epoch:100/56 Train MSELoss:0.7000806315437608\n",
      "Epochs/Epoch:100/56 Val MSELoss:75.04901531068569\n",
      "Epochs/Epoch:100/57 Train MSELoss:0.6826651413803515\n",
      "Epochs/Epoch:100/57 Val MSELoss:76.80209314953386\n",
      "Epochs/Epoch:100/58 Train MSELoss:0.6823576303279918\n",
      "Epochs/Epoch:100/58 Val MSELoss:80.05273006514979\n",
      "Epochs/Epoch:100/59 Train MSELoss:0.6824585362944914\n",
      "Epochs/Epoch:100/59 Val MSELoss:69.05212420847694\n",
      "Epochs/Epoch:100/60 Train MSELoss:0.6957783116756574\n",
      "Epochs/Epoch:100/60 Val MSELoss:74.48094943657127\n",
      "Epochs/Epoch:100/61 Train MSELoss:0.6979758525672166\n",
      "Epochs/Epoch:100/61 Val MSELoss:82.83022176311977\n",
      "Epochs/Epoch:100/62 Train MSELoss:0.6732213790326015\n",
      "Epochs/Epoch:100/62 Val MSELoss:78.27820742308498\n",
      "Epochs/Epoch:100/63 Train MSELoss:0.6758647298683291\n",
      "Epochs/Epoch:100/63 Val MSELoss:87.87830013183455\n",
      "Epochs/Epoch:100/64 Train MSELoss:0.7095803473468708\n",
      "Epochs/Epoch:100/64 Val MSELoss:78.41210771541746\n",
      "Epochs/Epoch:100/65 Train MSELoss:0.7083923883088257\n",
      "Epochs/Epoch:100/65 Val MSELoss:83.12359585678897\n",
      "Epochs/Epoch:100/66 Train MSELoss:0.6901787509736808\n",
      "Epochs/Epoch:100/66 Val MSELoss:90.6652781864323\n",
      "Epochs/Epoch:100/67 Train MSELoss:0.6996069305940814\n",
      "Epochs/Epoch:100/67 Val MSELoss:76.5796755842118\n",
      "Epochs/Epoch:100/68 Train MSELoss:0.6906111355385055\n",
      "Epochs/Epoch:100/68 Val MSELoss:83.59377582778036\n",
      "Epochs/Epoch:100/69 Train MSELoss:0.6916382379182007\n",
      "Epochs/Epoch:100/69 Val MSELoss:75.93751778847937\n",
      "Epochs/Epoch:100/70 Train MSELoss:0.7014474279206732\n",
      "Epochs/Epoch:100/70 Val MSELoss:78.20814050086899\n",
      "Epochs/Epoch:100/71 Train MSELoss:0.6683494384683992\n",
      "Epochs/Epoch:100/71 Val MSELoss:92.65878466166437\n",
      "Epochs/Epoch:100/72 Train MSELoss:0.6903332513959511\n",
      "Epochs/Epoch:100/72 Val MSELoss:80.83867308008587\n",
      "Epochs/Epoch:100/73 Train MSELoss:0.6879046035363622\n",
      "Epochs/Epoch:100/73 Val MSELoss:90.28379902911236\n",
      "Epochs/Epoch:100/74 Train MSELoss:0.6791912407168875\n",
      "Epochs/Epoch:100/74 Val MSELoss:88.17556760377035\n",
      "Epochs/Epoch:100/75 Train MSELoss:0.6817604206178499\n",
      "Epochs/Epoch:100/75 Val MSELoss:80.39585555920455\n",
      "Epochs/Epoch:100/76 Train MSELoss:0.6828500944311204\n",
      "Epochs/Epoch:100/76 Val MSELoss:93.98014759203188\n",
      "Epochs/Epoch:100/77 Train MSELoss:0.6764487556951202\n",
      "Epochs/Epoch:100/77 Val MSELoss:82.03131684265159\n",
      "Epochs/Epoch:100/78 Train MSELoss:0.6816513614486093\n",
      "Epochs/Epoch:100/78 Val MSELoss:96.43674560435036\n",
      "Epochs/Epoch:100/79 Train MSELoss:0.684011164728714\n",
      "Epochs/Epoch:100/79 Val MSELoss:84.28092214348321\n",
      "Epochs/Epoch:100/80 Train MSELoss:0.6742670825156181\n",
      "Epochs/Epoch:100/80 Val MSELoss:84.97793797666857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs/Epoch:100/81 Train MSELoss:0.6874668773101724\n",
      "Epochs/Epoch:100/81 Val MSELoss:79.49376222807844\n",
      "Epochs/Epoch:100/82 Train MSELoss:0.6869427356868982\n",
      "Epochs/Epoch:100/82 Val MSELoss:78.72069955448065\n",
      "Epochs/Epoch:100/83 Train MSELoss:0.6938327928276166\n",
      "Epochs/Epoch:100/83 Val MSELoss:92.8211955845559\n",
      "Epochs/Epoch:100/84 Train MSELoss:0.6947219133701014\n",
      "Epochs/Epoch:100/84 Val MSELoss:90.90867554366815\n",
      "Epochs/Epoch:100/85 Train MSELoss:0.690217441190844\n",
      "Epochs/Epoch:100/85 Val MSELoss:78.67467534675347\n",
      "Epochs/Epoch:100/86 Train MSELoss:0.6977795566553655\n",
      "Epochs/Epoch:100/86 Val MSELoss:83.5162721991104\n",
      "Epochs/Epoch:100/87 Train MSELoss:0.6903359904561354\n",
      "Epochs/Epoch:100/87 Val MSELoss:83.27617285591724\n",
      "Epochs/Epoch:100/88 Train MSELoss:0.6908829076944486\n",
      "Epochs/Epoch:100/88 Val MSELoss:80.55882895569363\n",
      "Epochs/Epoch:100/89 Train MSELoss:0.683044639132593\n",
      "Epochs/Epoch:100/89 Val MSELoss:78.55442195742688\n",
      "Epochs/Epoch:100/90 Train MSELoss:0.671990423746731\n",
      "Epochs/Epoch:100/90 Val MSELoss:87.34384648731412\n",
      "Epochs/Epoch:100/91 Train MSELoss:0.6796168680100337\n",
      "Epochs/Epoch:100/91 Val MSELoss:88.98934977720499\n",
      "Epochs/Epoch:100/92 Train MSELoss:0.6751690929674584\n",
      "Epochs/Epoch:100/92 Val MSELoss:78.81937707587876\n",
      "Epochs/Epoch:100/93 Train MSELoss:0.6700129443374665\n",
      "Epochs/Epoch:100/93 Val MSELoss:82.52372873554516\n",
      "Epochs/Epoch:100/94 Train MSELoss:0.6703395184291445\n",
      "Epochs/Epoch:100/94 Val MSELoss:72.25128673651886\n",
      "Epochs/Epoch:100/95 Train MSELoss:0.6730541931870191\n",
      "Epochs/Epoch:100/95 Val MSELoss:88.76045334931058\n",
      "Epochs/Epoch:100/96 Train MSELoss:0.6761604958092389\n",
      "Epochs/Epoch:100/96 Val MSELoss:79.32490869807917\n",
      "Epochs/Epoch:100/97 Train MSELoss:0.6806497862157614\n",
      "Epochs/Epoch:100/97 Val MSELoss:73.45871443146261\n",
      "Epochs/Epoch:100/98 Train MSELoss:0.6837359614994215\n",
      "Epochs/Epoch:100/98 Val MSELoss:71.42627943592186\n",
      "Epochs/Epoch:100/99 Train MSELoss:0.673237189569551\n",
      "Epochs/Epoch:100/99 Val MSELoss:88.03790871765098\n",
      "Epochs/Epoch:100/100 Train MSELoss:0.6649219609149124\n",
      "Epochs/Epoch:100/100 Val MSELoss:84.73185501257855\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 随机打乱训练集\n",
    "    seed = np.random.randint(10000)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_dataset)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(train_labels)\n",
    "    # 训练\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i in range(0, train_dataset.shape[0], batch_size):\n",
    "        batch_datas = paddle.to_tensor(train_dataset[i:batch_size+i].copy())\n",
    "        batch_labels = paddle.to_tensor(train_labels[i:batch_size+i].copy())\n",
    "        # print(batch_datas.shape, batch_labels.shape)\n",
    "        # 前向传播\n",
    "        preds = model(batch_datas)\n",
    "        # 计算损失\n",
    "        step_loss = loss(preds, batch_labels)\n",
    "        train_loss += step_loss.numpy()[0]\n",
    "        # 反向传播\n",
    "        step_loss.backward()\n",
    "        # 跟新参数\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "    print('Epochs/Epoch:{}/{} Train MSELoss:{}'.format(epochs, epoch+1, train_loss/(train_dataset.shape[0]//batch_size)))\n",
    "    # 验证\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    for i in range(val_dataset.shape[0]):\n",
    "        batch_datas = paddle.to_tensor(val_dataset[i:1+i].copy())\n",
    "        batch_labels = paddle.to_tensor(val_labels[i:1+i].copy())\n",
    "        # print(batch_datas.shape, batch_labels.shape)\n",
    "        # 前向传播\n",
    "        preds = model(batch_datas)\n",
    "        # 计算损失\n",
    "        val_loss += paddle.nn.functional.mse_loss(preds * label_std + label_mean, batch_labels* label_std + label_mean, reduction='sum').numpy()[0]\n",
    "    print('Epochs/Epoch:{}/{} Val MSELoss:{}'.format(epochs, epoch+1, val_loss/val_dataset.shape[0]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1000/1000 [00:01<00:00, 545.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "batch_size = 1\n",
    "model.eval()\n",
    "for i in tqdm(range(test_dataset.shape[0])):\n",
    "    batch_datas = paddle.to_tensor(test_dataset[i:batch_size+i].copy())\n",
    "    # 前向传播\n",
    "    preds = model(batch_datas)\n",
    "    scores.append(preds.squeeze().numpy() * label_std + label_mean)\n",
    "\n",
    "test_datas = pd.read_csv('./work/test.csv')\n",
    "eins = test_datas['ein'].values.tolist()\n",
    "\n",
    "results = pd.DataFrame({'ein':eins, 'score':scores})\n",
    "results.to_csv('./work/results.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
